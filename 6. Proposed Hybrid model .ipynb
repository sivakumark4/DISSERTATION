{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7de3d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c3db96",
   "metadata": {},
   "source": [
    "## Proposed Hybrid model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d78306",
   "metadata": {},
   "source": [
    "These are all the output csvs we got from our four models ANN, SARIMA , LOGISTIC REGRESSION AND ANN CLASSFICATION MODELS. These csvs are having pelds forecasted . these csvs are used as inputs for hybrid model. The content in this csvs are pelds forecasted by individual models throughout 2021.We are training our hybrid model with these csvs and comparing them with actual peak flags of 2021.\n",
    "\n",
    "These are all the csvs we are using as inputs :\n",
    "\n",
    "sarima_df = pd.read_csv('sarima_rolling_forecast5_flagged_daily999.csv')\n",
    "ann_forecast_df = pd.read_csv('actual_vs_forecast_with_datetimeANN_flagged_daily999.csv')\n",
    "logistic_regression_df = pd.read_csv('Logistic_Regression_PLED_Classification_Daily999.csv')\n",
    "ann_classification_df = pd.read_csv('Artificial_Neural_Network_PLED_Classification_Daily999.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3268594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Model  True Positive (TP)  True Negative (TN)  \\\n",
      "0                  SARIMA                  48                 284   \n",
      "1            ANN Forecast                  53                 282   \n",
      "2     Logistic Regression                  64                 222   \n",
      "3      ANN Classification                  52                 286   \n",
      "4  Meta Classifier Hybrid                  59                 283   \n",
      "\n",
      "   False Positive (FP)  False Negative (FN)  Accuracy (%)  Sensitivity (%)  \\\n",
      "0                   13                   20     90.958904        70.588235   \n",
      "1                   15                   15     91.780822        77.941176   \n",
      "2                   75                    4     78.356164        94.117647   \n",
      "3                   11                   16     92.602740        76.470588   \n",
      "4                   14                    9     93.698630        86.764706   \n",
      "\n",
      "   Inaccuracy (%)  \n",
      "0        9.041096  \n",
      "1        8.219178  \n",
      "2       21.643836  \n",
      "3        7.397260  \n",
      "4        6.301370  \n",
      "\n",
      "Results for Meta Classifier Hybrid Model:\n",
      "                              Meta Classifier Hybrid\n",
      "Number of Achieved Peaks                          59\n",
      "Number of Hybrid Model Peaks                      73\n",
      "\n",
      "Actual and Hybrid peak flags saved to 'actual_vs_hybrid_peak_flags.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tn/v941jp4540374j7s4hp2b37w0000gn/T/ipykernel_43550/365307018.py:134: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  output_df.rename(columns={'Meta_Classifier_Prediction': 'Hybrid_Peak_Flag'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Loading the output CSV files from all the models\n",
    "sarima_df = pd.read_csv('sarima_rolling_forecast5_flagged_daily999.csv')\n",
    "ann_forecast_df = pd.read_csv('actual_vs_forecast_with_datetimeANN_flagged_daily999.csv')\n",
    "logistic_regression_df = pd.read_csv('Logistic_Regression_PLED_Classification_Daily999.csv')\n",
    "ann_classification_df = pd.read_csv('Artificial_Neural_Network_PLED_Classification_Daily999.csv')\n",
    "\n",
    "# Merging all dataframes on the Date column to prepare for the hybrid model\n",
    "combined_df = sarima_df[['Date', 'Actual_Peak_Flag']].copy()\n",
    "combined_df = combined_df.merge(sarima_df[['Date', 'Forecast_Peak_Flag']], on='Date', suffixes=('', '_SARIMA'))\n",
    "combined_df = combined_df.merge(ann_forecast_df[['Date', 'Forecast_Peak_Flag']], on='Date', suffixes=('', '_ANN_Forecast'))\n",
    "combined_df = combined_df.merge(logistic_regression_df[['Date', 'PLED_Prediction']], on='Date', suffixes=('', '_Logistic'))\n",
    "combined_df = combined_df.merge(ann_classification_df[['Date', 'PLED_Prediction']], on='Date', suffixes=('', '_ANN_Classification'))\n",
    "\n",
    "# Renaming columns for clarity\n",
    "combined_df.rename(columns={\n",
    "    'Forecast_Peak_Flag': 'SARIMA_Prediction',\n",
    "    'Forecast_Peak_Flag_ANN_Forecast': 'ANN_Forecast_Prediction',\n",
    "    'PLED_Prediction': 'Logistic_Prediction',\n",
    "    'PLED_Prediction_ANN_Classification': 'ANN_Classification_Prediction'\n",
    "}, inplace=True)\n",
    "\n",
    "# Helper function to create confusion matrix as a dictionary\n",
    "def calculate_confusion_matrix(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return {\n",
    "        'True Positive (TP)': tp,\n",
    "        'True Negative (TN)': tn,\n",
    "        'False Positive (FP)': fp,\n",
    "        'False Negative (FN)': fn\n",
    "    }\n",
    "\n",
    "# Helper function to calculate performance metrics\n",
    "def calculate_metrics(conf_matrix):\n",
    "    tp = conf_matrix['True Positive (TP)']\n",
    "    tn = conf_matrix['True Negative (TN)']\n",
    "    fp = conf_matrix['False Positive (FP)']\n",
    "    fn = conf_matrix['False Negative (FN)']\n",
    "    \n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    inaccuracy = (fp + fn) / (tp + tn + fp + fn)\n",
    "    \n",
    "    return {\n",
    "        'Accuracy': accuracy,\n",
    "        'Sensitivity': sensitivity,\n",
    "        'Inaccuracy': inaccuracy\n",
    "    }\n",
    "\n",
    "# Calculating confusion matrices and metrics for individual models\n",
    "sarima_results = calculate_confusion_matrix(combined_df['Actual_Peak_Flag'], combined_df['SARIMA_Prediction'])\n",
    "sarima_metrics = calculate_metrics(sarima_results)\n",
    "\n",
    "ann_forecast_results = calculate_confusion_matrix(combined_df['Actual_Peak_Flag'], combined_df['ANN_Forecast_Prediction'])\n",
    "ann_forecast_metrics = calculate_metrics(ann_forecast_results)\n",
    "\n",
    "logistic_results = calculate_confusion_matrix(combined_df['Actual_Peak_Flag'], combined_df['Logistic_Prediction'])\n",
    "logistic_metrics = calculate_metrics(logistic_results)\n",
    "\n",
    "ann_classification_results = calculate_confusion_matrix(combined_df['Actual_Peak_Flag'], combined_df['ANN_Classification_Prediction'])\n",
    "ann_classification_metrics = calculate_metrics(ann_classification_results)\n",
    "\n",
    "# Creating a dataframe to display the confusion matrices and metrics for individual models\n",
    "data = {\n",
    "    'Model': ['SARIMA', 'ANN Forecast', 'Logistic Regression', 'ANN Classification'],\n",
    "    'True Positive (TP)': [sarima_results['True Positive (TP)'], ann_forecast_results['True Positive (TP)'],\n",
    "                           logistic_results['True Positive (TP)'], ann_classification_results['True Positive (TP)']],\n",
    "    'True Negative (TN)': [sarima_results['True Negative (TN)'], ann_forecast_results['True Negative (TN)'],\n",
    "                           logistic_results['True Negative (TN)'], ann_classification_results['True Negative (TN)']],\n",
    "    'False Positive (FP)': [sarima_results['False Positive (FP)'], ann_forecast_results['False Positive (FP)'],\n",
    "                            logistic_results['False Positive (FP)'], ann_classification_results['False Positive (FP)']],\n",
    "    'False Negative (FN)': [sarima_results['False Negative (FN)'], ann_forecast_results['False Negative (FN)'],\n",
    "                            logistic_results['False Negative (FN)'], ann_classification_results['False Negative (FN)']],\n",
    "    'Accuracy (%)': [sarima_metrics['Accuracy'] * 100, ann_forecast_metrics['Accuracy'] * 100,\n",
    "                     logistic_metrics['Accuracy'] * 100, ann_classification_metrics['Accuracy'] * 100],\n",
    "    'Sensitivity (%)': [sarima_metrics['Sensitivity'] * 100, ann_forecast_metrics['Sensitivity'] * 100,\n",
    "                        logistic_metrics['Sensitivity'] * 100, ann_classification_metrics['Sensitivity'] * 100],\n",
    "    'Inaccuracy (%)': [sarima_metrics['Inaccuracy'] * 100, ann_forecast_metrics['Inaccuracy'] * 100,\n",
    "                       logistic_metrics['Inaccuracy'] * 100, ann_classification_metrics['Inaccuracy'] * 100]\n",
    "}\n",
    "\n",
    "# Meta-Learning using RandomForestClassifier\n",
    "# Prepare the features for the meta-classifier\n",
    "X_meta = combined_df[['SARIMA_Prediction', 'ANN_Forecast_Prediction', 'Logistic_Prediction', 'ANN_Classification_Prediction']]\n",
    "y_meta = combined_df['Actual_Peak_Flag']\n",
    "\n",
    "# Training a RandomForestClassifier as the meta-classifier\n",
    "meta_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "meta_clf.fit(X_meta, y_meta)\n",
    "\n",
    "# Making predictions using the meta-classifier\n",
    "combined_df['Meta_Classifier_Prediction'] = meta_clf.predict(X_meta)\n",
    "\n",
    "# Calculating confusion matrix and metrics for meta-classifier hybrid model\n",
    "meta_classifier_results = calculate_confusion_matrix(combined_df['Actual_Peak_Flag'], combined_df['Meta_Classifier_Prediction'])\n",
    "meta_classifier_metrics = calculate_metrics(meta_classifier_results)\n",
    "\n",
    "# Addding Meta Classifier results to the dataframe\n",
    "data['Model'].append('Meta Classifier Hybrid')\n",
    "data['True Positive (TP)'].append(meta_classifier_results['True Positive (TP)'])\n",
    "data['True Negative (TN)'].append(meta_classifier_results['True Negative (TN)'])\n",
    "data['False Positive (FP)'].append(meta_classifier_results['False Positive (FP)'])\n",
    "data['False Negative (FN)'].append(meta_classifier_results['False Negative (FN)'])\n",
    "data['Accuracy (%)'].append(meta_classifier_metrics['Accuracy'] * 100)\n",
    "data['Sensitivity (%)'].append(meta_classifier_metrics['Sensitivity'] * 100)\n",
    "data['Inaccuracy (%)'].append(meta_classifier_metrics['Inaccuracy'] * 100)\n",
    "\n",
    "# Displaying the results in a table format\n",
    "results_df = pd.DataFrame(data)\n",
    "print(results_df)\n",
    "\n",
    "# Calculating the number of actual peaks, hybrid model peaks, and achieved peaks for Meta Classifier Hybrid\n",
    "meta_classifier_peaks = combined_df['Meta_Classifier_Prediction'].sum()\n",
    "achieved_peaks_meta = ((combined_df['Meta_Classifier_Prediction'] == 1) & (combined_df['Actual_Peak_Flag'] == 1)).sum()\n",
    "\n",
    "# Output the results for Meta Classifier Hybrid model\n",
    "results = {\n",
    "    'Meta Classifier Hybrid': {\n",
    "        'Number of Hybrid Model Peaks': meta_classifier_peaks,\n",
    "        'Number of Achieved Peaks': achieved_peaks_meta\n",
    "    }\n",
    "}\n",
    "\n",
    "# Displaying results for Meta Classifier Hybrid model\n",
    "print(\"\\nResults for Meta Classifier Hybrid Model:\")\n",
    "print(pd.DataFrame(results))\n",
    "\n",
    "# Saving actual and hybrid peak flags in a CSV with the date column\n",
    "output_df = combined_df[['Date', 'Actual_Peak_Flag', 'Meta_Classifier_Prediction']]\n",
    "output_df.rename(columns={'Meta_Classifier_Prediction': 'Hybrid_Peak_Flag'}, inplace=True)\n",
    "output_df.to_csv('actual_vs_hybrid_peak_flags.csv', index=False)\n",
    "\n",
    "# Printing message indicating that the file has been saved\n",
    "print(\"\\nActual and Hybrid peak flags saved to 'actual_vs_hybrid_peak_flags.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0786e51",
   "metadata": {},
   "source": [
    "#### RESULT :\n",
    "    Results for Meta Classifier Hybrid Model:\n",
    "                              Meta Classifier Hybrid\n",
    "               Number of Achieved Peaks                          59\n",
    "               Number of Hybrid Model Peaks                      73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e038671",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
